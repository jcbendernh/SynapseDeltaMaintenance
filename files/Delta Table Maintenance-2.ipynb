{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Delta Table Maintenance Part 2 - Optimize and Vacuum\r\n",
        "\r\n",
        "This Notebook is used to perform maintenance tasks on the Delta Table via the Delta Table Maintenance Pipeline. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declare the parameters that are passed onto the other cells later in the notebook\r\n",
        "These are passed into the notebook from the pipeline."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_namespace = ''\r\n",
        "p_tableName = ''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\r\n",
        "### Declare the values to pass on the other cells later in the notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession \r\n",
        "from pyspark.sql.types import * \r\n",
        "from delta.tables import DeltaTable\r\n",
        "from notebookutils import mssparkutils\r\n",
        "\r\n",
        "# Delta Table Settings\r\n",
        "spark.conf.set(\"sql.delta_schema\", p_namespace) #Delta Table schema\r\n",
        "spark.conf.set(\"sql.delta_table\", p_tableName) #Delta Table Name\r\n",
        "spark.conf.set(\"sql.vacuum_hours\", '168' )  # Vacuum setting for the Delta Table"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimize Table\r\n",
        "For more on this command, check out https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/delta-optimize"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "OPTIMIZE ${sql.delta_schema}.${sql.delta_table}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vacuum table\r\n",
        "Vacuum hours is set in the first cell <BR>\r\n",
        "For more on this topic check out https://learn.microsoft.com/en-us/azure/databricks/delta/vacuum"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "\r\n",
        "VACUUM ${sql.delta_schema}.${sql.delta_table} RETAIN ${sql.vacuum_hours} HOURS"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}